# –ß–∞—Å–æ–≤—ñ —Ä—è–¥–∏ —Ç–∞ IoT —Å–∏—Å—Ç–µ–º–∏

## –ü–ª–∞–Ω –ª–µ–∫—Ü—ñ—ó

1. –°–ø–µ—Ü–∏—Ñ—ñ–∫–∞ —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤
2. –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ time-series –±–∞–∑ –¥–∞–Ω–∏—Ö
3. –ö–æ–º–ø—Ä–µ—Å—ñ—è —Ç–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
4. Internet of Things: –∑–±—ñ—Ä —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è
5. Edge computing —Ç–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞

## –©–æ —Ç–∞–∫–µ —á–∞—Å–æ–≤—ñ —Ä—è–¥–∏?

**–ß–∞—Å–æ–≤–∏–π —Ä—è–¥** ‚Äî –≤–ø–æ—Ä—è–¥–∫–æ–≤–∞–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å —á–∏—Å–ª–æ–≤–∏—Ö –∑–Ω–∞—á–µ–Ω—å, –∫–æ–∂–Ω–µ –∑ —è–∫–∏—Ö –∞—Å–æ—Ü—ñ–π–æ–≤–∞–Ω–µ –∑ –ø–µ–≤–Ω–∏–º –º–æ–º–µ–Ω—Ç–æ–º —á–∞—Å—É.

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ:** {(t‚ÇÅ, v‚ÇÅ), (t‚ÇÇ, v‚ÇÇ), ..., (t‚Çô, v‚Çô)}

```mermaid
graph LR
    A[üìä –î–∂–µ—Ä–µ–ª–æ] -->|t‚ÇÅ, v‚ÇÅ| B[–¢–æ—á–∫–∞ 1]
    A -->|t‚ÇÇ, v‚ÇÇ| C[–¢–æ—á–∫–∞ 2]
    A -->|t‚ÇÉ, v‚ÇÉ| D[–¢–æ—á–∫–∞ 3]
    A -->|t‚Çô, v‚Çô| E[–¢–æ—á–∫–∞ n]

    B --> F[‚è±Ô∏è –ß–∞—Å–æ–≤–∏–π —Ä—è–¥]
    C --> F
    D --> F
    E --> F
```

**–ü—Ä–∏–∫–ª–∞–¥–∏:**
- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–µ–Ω—Å–æ—Ä—ñ–≤ –∫–æ–∂–Ω—ñ 10 —Å–µ–∫—É–Ω–¥
- –¶—ñ–Ω–∏ –∞–∫—Ü—ñ–π —â–æ—Ö–≤–∏–ª–∏–Ω–∏
- –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ—Ä–≤–µ—Ä—ñ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ

## –û—Å–Ω–æ–≤–Ω—ñ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤

### üîÑ **–ú–æ–Ω–æ—Ç–æ–Ω–Ω—ñ—Å—Ç—å —á–∞—Å—É**

t·µ¢ < t·µ¢‚Çä‚ÇÅ ‚Äî —á–∞—Å–æ–≤—ñ –ø–æ–∑–Ω–∞—á–∫–∏ –∑–∞–≤–∂–¥–∏ –∑—Ä–æ—Å—Ç–∞—é—Ç—å

### üìç **–û–±–æ–≤'—è–∑–∫–æ–≤–∞ —á–∞—Å–æ–≤–∞ –ø—Ä–∏–≤'—è–∑–∫–∞**

–ë–µ–∑ —á–∞—Å–æ–≤–æ—ó –ø–æ–∑–Ω–∞—á–∫–∏ –¥–∞–Ω—ñ –≤—Ç—Ä–∞—á–∞—é—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç

### üîí **–ù–µ–∑–º—ñ–Ω–Ω—ñ—Å—Ç—å —ñ—Å—Ç–æ—Ä—ñ—ó**

–ú–∏–Ω—É–ª–µ –Ω–µ –∑–º—ñ–Ω—é—î—Ç—å—Å—è ‚Äî —Ä—ñ–¥–∫—ñ—Å–Ω—ñ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è

### ‚ö° **–í–∏—Å–æ–∫–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–¥—Ö–æ–¥–∂–µ–Ω–Ω—è**

–¢–∏—Å—è—á—ñ-–º—ñ–ª—å–π–æ–Ω–∏ —Ç–æ—á–æ–∫ –¥–∞–Ω–∏—Ö –Ω–∞ —Å–µ–∫—É–Ω–¥—É

## –¢–∏–ø–∏ —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤

### üìÖ **–†–µ–≥—É–ª—è—Ä–Ω—ñ —á–∞—Å–æ–≤—ñ —Ä—è–¥–∏**

–§—ñ–∫—Å–æ–≤–∞–Ω—ñ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏ –º—ñ–∂ –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è–º–∏

```sql
-- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∫–æ–∂–Ω—ñ 10 —Å–µ–∫—É–Ω–¥
CREATE TABLE temperature_readings (
    sensor_id INTEGER,
    measured_at TIMESTAMP NOT NULL,
    temperature_celsius DECIMAL(5,2),
    PRIMARY KEY (sensor_id, measured_at)
);

INSERT INTO temperature_readings VALUES
    (101, '2025-01-15 10:00:00', 22.5),
    (101, '2025-01-15 10:00:10', 22.6),
    (101, '2025-01-15 10:00:20', 22.4);
```

### üéØ **–ù–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ñ —á–∞—Å–æ–≤—ñ —Ä—è–¥–∏**

–ó–º—ñ–Ω–Ω—ñ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏, —Ä–µ–∞–≥—É–≤–∞–Ω–Ω—è –Ω–∞ –ø–æ–¥—ñ—ó

## –í–∏–∫–ª–∏–∫–∏ —Ä–æ–±–æ—Ç–∏ –∑ —á–∞—Å–æ–≤–∏–º–∏ —Ä—è–¥–∞–º–∏

### üíæ **–í–∏—Å–æ–∫–∏–π –æ–±'—î–º –¥–∞–Ω–∏—Ö**

**1 –¥–∞—Ç—á–∏–∫, 1 —Å —ñ–Ω—Ç–µ—Ä–≤–∞–ª:**
- 86,400 –∑–∞–ø–∏—Å—ñ–≤/–¥–µ–Ω—å
- 2.6M –∑–∞–ø–∏—Å—ñ–≤/–º—ñ—Å—è—Ü—å
- 31.5M –∑–∞–ø–∏—Å—ñ–≤/—Ä—ñ–∫

**–ü—Ä–∏ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—ñ –Ω–∞ —Ç–∏—Å—è—á—ñ –¥–∞—Ç—á–∏–∫—ñ–≤ ‚Äî –∞—Å—Ç—Ä–æ–Ω–æ–º—ñ—á–Ω—ñ –æ–±—Å—è–≥–∏**

### ‚ö° **–®–≤–∏–¥–∫–∏–π –∑–∞–ø–∏—Å**

–¢—Ä–∞–¥–∏—Ü—ñ–π–Ω—ñ B-tree —ñ–Ω–¥–µ–∫—Å–∏ –Ω–µ–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ

### üóúÔ∏è **–ù–µ–æ–±—Ö—ñ–¥–Ω—ñ—Å—Ç—å –∫–æ–º–ø—Ä–µ—Å—ñ—ó**

–í–∏—Å–æ–∫–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ —Å—É—Å—ñ–¥–Ω—ñ–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏

### üî• **–ì–∞—Ä—è—á—ñ vs –•–æ–ª–æ–¥–Ω—ñ –¥–∞–Ω—ñ**

–ë–∞–≥–∞—Ç–æ—Ä—ñ–≤–Ω–µ–≤–µ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –±–∞–∑ –¥–∞–Ω–∏—Ö –¥–ª—è —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤

### üìä **InfluxDB**

–°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –ë–î –¥–ª—è —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤

**–ö–ª—é—á–æ–≤—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ:**
- Log-structured merge-tree
- –í–ª–∞—Å–Ω–∞ –º–æ–≤–∞ Flux
- Retention policies
- –¢–µ–≥–∏ –¥–ª—è —ñ–Ω–¥–µ–∫—Å—É–≤–∞–Ω–Ω—è

```
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–æ—á–∫–∏ –¥–∞–Ω–∏—Ö
measurement,tag_key=tag_value field_key=field_value timestamp

# –ü—Ä–∏–∫–ª–∞–¥
temperature,sensor=sensor_01,location=room_1 value=22.5 1642248000000000000

# –î–µ–∫—ñ–ª—å–∫–∞ –ø–æ–ª—ñ–≤
weather,location=kyiv temperature=15.2,humidity=65,pressure=1013
```

## InfluxDB: Flux –∑–∞–ø–∏—Ç–∏

```sql
-- –°–µ—Ä–µ–¥–Ω—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∑–∞ –≥–æ–¥–∏–Ω—É
from(bucket: "sensors")
  |> range(start: -1h)
  |> filter(fn: (r) => r._measurement == "temperature")
  |> filter(fn: (r) => r.sensor == "sensor_01")
  |> aggregateWindow(every: 5m, fn: mean)
  |> yield(name: "mean_temperature")

-- Retention policy
CREATE RETENTION POLICY "one_week" ON "sensors"
    DURATION 7d
    REPLICATION 1
    DEFAULT
```

**‚úÖ –ü–µ—Ä–µ–≤–∞–≥–∏:** –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å, –≤–±—É–¥–æ–≤–∞–Ω–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞
**‚ö†Ô∏è –ù–µ–¥–æ–ª—ñ–∫–∏:** –ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –º–æ–≤–∞ –∑–∞–ø–∏—Ç—ñ–≤

## TimescaleDB

**PostgreSQL + Time-Series –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó**

### üîÑ **–ì—ñ–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—ñ (Hypertables)**

–í–∏–≥–ª—è–¥–∞—î —è–∫ –∑–≤–∏—á–∞–π–Ω–∞ —Ç–∞–±–ª–∏—Ü—è, –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –ø–∞—Ä—Ç–∏—Ü—ñ–æ–Ω—É–≤–∞–Ω–Ω—è

```sql
-- –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ
CREATE TABLE sensor_data (
    time TIMESTAMPTZ NOT NULL,
    sensor_id INTEGER NOT NULL,
    temperature DOUBLE PRECISION,
    humidity DOUBLE PRECISION
);

-- –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞ –≥—ñ–ø–µ—Ä—Ç–∞–±–ª–∏—Ü—é
SELECT create_hypertable('sensor_data', 'time');

-- –ü—Ä–∞—Ü—é—î —è–∫ –∑–≤–∏—á–∞–π–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
INSERT INTO sensor_data VALUES (NOW(), 1, 22.5, 65);
SELECT * FROM sensor_data WHERE time > NOW() - INTERVAL '1 hour';
```

## TimescaleDB: –ö–æ–º–ø—Ä–µ—Å—ñ—è —Ç–∞ –ø–æ–ª—ñ—Ç–∏–∫–∏

```sql
-- –£–≤—ñ–º–∫–Ω–µ–Ω–Ω—è –∫–æ–º–ø—Ä–µ—Å—ñ—ó
ALTER TABLE sensor_data SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'sensor_id',
    timescaledb.compress_orderby = 'time DESC'
);

-- –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –∫–æ–º–ø—Ä–µ—Å—ñ—è —á–µ—Ä–µ–∑ 7 –¥–Ω—ñ–≤
SELECT add_compression_policy('sensor_data', INTERVAL '7 days');

-- Retention policy
SELECT add_retention_policy('sensor_data', INTERVAL '90 days');
```

**üéØ –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∫–æ–º–ø—Ä–µ—Å—ñ—ó: 90-95%**

## –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è InfluxDB vs TimescaleDB

```mermaid
graph TB
    A[ü§î –í–∏–º–æ–≥–∏ –ø—Ä–æ—î–∫—Ç—É] --> B{–¢–∏–ø –¥–∞–Ω–∏—Ö}
    B -->|–ß–∏—Å—Ç—ñ Time-Series| C[üí° InfluxDB]
    B -->|–ì—ñ–±—Ä–∏–¥–Ω—ñ + —Ä–µ–ª—è—Ü—ñ–π–Ω—ñ| D[üêò TimescaleDB]

    C --> E1[–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å]
    C --> E2[–í–±—É–¥–æ–≤–∞–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó]
    C --> E3[–ü—Ä–æ—Å—Ç–∞ –º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ—Å—Ç—å]

    D --> F1[–ó–Ω–∞–π–æ–º–∏–π SQL]
    D --> F2[JOIN –∑ —Ç–∞–±–ª–∏—Ü—è–º–∏]
    D --> F3[–ï–∫–æ—Å–∏—Å—Ç–µ–º–∞ PostgreSQL]
```

## –ú–µ—Ç–æ–¥–∏ –∫–æ–º–ø—Ä–µ—Å—ñ—ó —á–∞—Å–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö

### üìâ **Delta Encoding**

–ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ü—å –∑–∞–º—ñ—Å—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å

```python
original_values = [1000, 1005, 1003, 1007, 1010, 1008]

base_value = 1000
deltas = [5, -2, 4, 3, -2]

# –ï–∫–æ–Ω–æ–º—ñ—è –ø—Ä–æ—Å—Ç–æ—Ä—É –∑–∞ —Ä–∞—Ö—É–Ω–æ–∫ –º–µ–Ω—à–∏—Ö —á–∏—Å–µ–ª
```

### üî§ **Dictionary Encoding**

–°–ª–æ–≤–Ω–∏–∫ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å + –∫–æ–º–ø–∞–∫—Ç–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è

### ‚ö° **Gorilla Compression**

XOR –æ–ø–µ—Ä–∞—Ü—ñ—ó –¥–ª—è –ø–ª–∞–≤–∞—é—á–æ—ó –∫–æ–º–∏ (Facebook)

**–¢–∏–ø–æ–≤–∏–π –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç: 10-20x –∫–æ–º–ø—Ä–µ—Å—ñ—è**

## –ë–∞–≥–∞—Ç–æ—Ä—ñ–≤–Ω–µ–≤–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è

```mermaid
graph TD
    A[üìä –ü–µ—Ä–≤–∏–Ω–Ω—ñ –¥–∞–Ω—ñ<br/>1 —Å–µ–∫—É–Ω–¥–∞] --> B[üìà –ê–≥—Ä–µ–≥–∞—Ç 1 —Ö–≤]
    B --> C[üìä –ê–≥—Ä–µ–≥–∞—Ç 1 –≥–æ–¥]
    C --> D[üìÖ –ê–≥—Ä–µ–≥–∞—Ç 1 –¥–µ–Ω—å]
    D --> E[üìÜ –ê–≥—Ä–µ–≥–∞—Ç 1 –º—ñ—Å]

    A --> F[üî• 7 –¥–Ω—ñ–≤]
    B --> G[üíæ 30 –¥–Ω—ñ–≤]
    C --> H[üíø 1 —Ä—ñ–∫]
    D --> I[üìÄ 5 —Ä–æ–∫—ñ–≤]
    E --> J[‚òÅÔ∏è –ù–∞–∑–∞–≤–∂–¥–∏]
```

**–ü—Ä–∏–Ω—Ü–∏–ø:** –î–µ—Ç–∞–ª—ñ —Å–≤—ñ–∂—ñ, —ñ—Å—Ç–æ—Ä—ñ—è –∞–≥—Ä–µ–≥–æ–≤–∞–Ω–∞

## Continuous Aggregates –≤ TimescaleDB

```sql
-- –©–æ—Ö–≤–∏–ª–∏–Ω–Ω—ñ –∞–≥—Ä–µ–≥–∞—Ç–∏
CREATE MATERIALIZED VIEW sensor_data_1min
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 minute', time) AS minute,
    sensor_id,
    avg(temperature) as avg_temp,
    min(temperature) as min_temp,
    max(temperature) as max_temp,
    count(*) as sample_count
FROM sensor_data
GROUP BY minute, sensor_id;

-- –ü–æ–ª—ñ—Ç–∏–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è
SELECT add_continuous_aggregate_policy('sensor_data_1min',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');
```

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ IoT —Å–∏—Å—Ç–µ–º

```mermaid
graph TB
    A[üîå –ü—Ä–∏—Å—Ç—Ä–æ—ó<br/>Sensors] --> B[üì° –ó–≤'—è–∑–æ–∫<br/>MQTT, CoAP]
    B --> C[üåê –®–ª—é–∑–∏<br/>Edge]
    C --> D[‚òÅÔ∏è –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞<br/>IoT Platform]
    D --> E[üíæ –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è<br/>Time-Series DB]
    E --> F[üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞<br/>Real-time]
    F --> G[üì± –î–æ–¥–∞—Ç–∫–∏<br/>Dashboards]

    C -.->|Edge Analytics| H[üîß –õ–æ–∫–∞–ª—å–Ω–∞ –ë–î]
    H -.->|Sync| E
```

## MQTT: –ü—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è IoT

**Message Queuing Telemetry Transport** ‚Äî –ª–µ–≥–∫–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª pub/sub

```python
# MQTT –∫–ª—ñ—î–Ω—Ç –Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—ó
import paho.mqtt.client as mqtt
import json

class IoTSensor:
    def __init__(self, sensor_id, broker):
        self.sensor_id = sensor_id
        self.client = mqtt.Client()
        self.client.connect(broker, 1883, 60)

    def publish_data(self):
        data = {
            'sensor_id': self.sensor_id,
            'timestamp': datetime.utcnow().isoformat(),
            'temperature': 22.5,
            'humidity': 65
        }
        topic = f"sensors/{self.sensor_id}/data"
        self.client.publish(topic, json.dumps(data))
```

**‚úÖ –ü–µ—Ä–µ–≤–∞–≥–∏:** –õ–µ–≥–∫–∏–π, –Ω–∞–¥—ñ–π–Ω–∏–π, –º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω–∏–π

## –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö –≤—ñ–¥ IoT –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤

```python
# MQTT –±—Ä–æ–∫–µ—Ä + InfluxDB
class IoTDataCollector:
    def __init__(self):
        self.mqtt_client = mqtt.Client()
        self.mqtt_client.on_message = self.on_message
        self.mqtt_client.subscribe("sensors/+/data")

        self.influx_client = InfluxDBClient(url="http://localhost:8086")

    def on_message(self, client, userdata, msg):
        data = json.loads(msg.payload)

        # –ó–∞–ø–∏—Å –≤ InfluxDB
        point = Point("sensor_reading") \
            .tag("sensor_id", data['sensor_id']) \
            .field("temperature", data['temperature']) \
            .field("humidity", data['humidity']) \
            .time(data['timestamp'])

        self.influx_client.write(bucket="sensors", record=point)
```

## –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ

```python
class BatchedCollector:
    def __init__(self, batch_size=1000, flush_interval=60):
        self.batch = []
        self.batch_size = batch_size
        self.flush_interval = flush_interval

    def add_reading(self, data):
        self.batch.append(data)

        # Flush –ø—Ä–∏ –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—ñ —Ä–æ–∑–º—ñ—Ä—É –∞–±–æ —á–∞—Å—É
        if (len(self.batch) >= self.batch_size or
            time.time() - self.last_flush >= self.flush_interval):
            self.flush()

    def flush(self):
        # –ü–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Å –≤ –ë–î
        self.influx_client.write(bucket="sensors", record=self.batch)
        self.batch = []
```

**üìä –ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å: 100x –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è vs –æ–¥–∏–Ω–æ—á–Ω—ñ –∑–∞–ø–∏—Å–∏**

## –ü–æ—Ç–æ–∫–æ–≤–∞ –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö

### ‚ö° **Apache Kafka –¥–ª—è IoT**

```python
# Stream processing –∑ Kafka
class IoTStreamProcessor:
    def __init__(self):
        self.consumer = KafkaConsumer('sensor-raw-data')
        self.producer = KafkaProducer('sensor-alerts')

    def process_stream(self):
        window_buffer = []

        for message in self.consumer:
            data = message.value
            window_buffer.append(data)

            # –ö–æ–≤–∑–Ω–µ –≤—ñ–∫–Ω–æ
            if len(window_buffer) == 10:
                avg_temp = sum(d['temperature'] for d in window_buffer) / 10

                # –í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π
                if abs(data['temperature'] - avg_temp) > 5:
                    alert = {'sensor_id': data['sensor_id'],
                             'anomaly': 'temperature'}
                    self.producer.send('sensor-alerts', alert)
```

## –í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ

### üìä **Z-Score –º–µ—Ç–æ–¥**

```python
class AnomalyDetector:
    def __init__(self, window_size=100, threshold=3.0):
        self.window = deque(maxlen=window_size)
        self.threshold = threshold

    def detect(self, value):
        self.window.append(value)

        if len(self.window) < window_size:
            return False

        mean = np.mean(self.window)
        std = np.std(self.window)

        z_score = abs((value - mean) / std)
        return z_score > self.threshold

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
detector = AnomalyDetector()
if detector.detect(reading['temperature']):
    print(f"üö® –ê–Ω–æ–º–∞–ª—ñ—è: {reading['temperature']}")
```

## Edge Computing: –ö–æ–Ω—Ü–µ–ø—Ü—ñ—è

**–û–±—á–∏—Å–ª–µ–Ω–Ω—è –Ω–∞ –∫—Ä–∞—é –º–µ—Ä–µ–∂—ñ** ‚Äî –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö –±–ª–∏–∂—á–µ –¥–æ –¥–∂–µ—Ä–µ–ª

```mermaid
graph TB
    A[üì± IoT –ü—Ä–∏—Å—Ç—Ä–æ—ó] --> B[üåê Edge Gateway]
    B --> C{–õ–æ–∫–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞}
    C -->|–ö—Ä–∏—Ç–∏—á–Ω–æ| D[‚öôÔ∏è –ê–∫—Ç—É–∞—Ç–æ—Ä–∏]
    C -->|–ê–≥—Ä–µ–≥–æ–≤–∞–Ω–æ| E[‚òÅÔ∏è –•–º–∞—Ä–∞]
    C -->|–¢—Ä–∏–≤–æ–≥–∏| F[üì¢ –õ–æ–∫–∞–ª—å–Ω—ñ —Å–µ—Ä–≤—ñ—Å–∏]

    B --> G[üíæ –õ–æ–∫–∞–ª—å–Ω–∞ –ë–î]
    G -.->|Sync| E

    E --> H[üìä –ì–ª–æ–±–∞–ª—å–Ω–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞]
    E --> I[ü§ñ ML –º–æ–¥–µ–ª—ñ]
    I -.->|–û–Ω–æ–≤–ª–µ–Ω–Ω—è| B
```

## –ü–µ—Ä–µ–≤–∞–≥–∏ Edge Computing

### ‚ö° **–ó–Ω–∏–∂–µ–Ω–∞ –ª–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å**

–ú–∏—Ç—Ç—î–≤—ñ —Ä—ñ—à–µ–Ω–Ω—è –±–µ–∑ –∑–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ —Ö–º–∞—Ä–∏

### üì° **–ï–∫–æ–Ω–æ–º—ñ—è –ø—Ä–æ–ø—É—Å–∫–Ω–æ—ó –∑–¥–∞—Ç–Ω–æ—Å—Ç—ñ**

–õ–æ–∫–∞–ª—å–Ω–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è

### üîí **–ü—ñ–¥–≤–∏—â–µ–Ω–∞ –ø—Ä–∏–≤–∞—Ç–Ω—ñ—Å—Ç—å**

–ß—É—Ç–ª–∏–≤—ñ –¥–∞–Ω—ñ –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –ª–æ–∫–∞–ª—å–Ω–æ

### üîÑ **–ê–≤—Ç–æ–Ω–æ–º–Ω—ñ—Å—Ç—å**

–†–æ–±–æ—Ç–∞ –ø—Ä–∏ –≤—Ç—Ä–∞—Ç—ñ –∑–≤'—è–∑–∫—É –∑ —Ö–º–∞—Ä–æ—é

## Edge Gateway: –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```python
class EdgeGateway:
    def __init__(self):
        self.local_db = sqlite3.connect('edge_buffer.db')
        self.decision_rules = self.load_rules()

    def process_reading(self, reading):
        # 1. –õ–æ–∫–∞–ª—å–Ω–µ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è
        self.store_locally(reading)

        # 2. –õ–æ–∫–∞–ª—å–Ω–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞
        analysis = self.analyze_locally(reading)

        # 3. –ö—Ä–∏—Ç–∏—á–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è
        if analysis['requires_action']:
            self.take_local_action(analysis)

        # 4. –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è –∑ —Ö–º–∞—Ä–æ—é
        if analysis['should_sync']:
            self.queue_for_sync(reading)

    def analyze_locally(self, reading):
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ—Ä–æ–≥—ñ–≤ –±–µ–∑ –∑–≤–µ—Ä–Ω–µ–Ω–Ω—è –¥–æ —Ö–º–∞—Ä–∏
        recent_avg = self.get_recent_average(reading['sensor_id'])

        if abs(reading['value'] - recent_avg) > threshold:
            return {'requires_action': True, 'alert': 'sudden_change'}
```

## –§–µ–¥–µ—Ä–æ–≤–∞–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

**–ù–∞–≤—á–∞–Ω–Ω—è ML –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö**

```python
class FederatedLearningNode:
    def __init__(self, node_id):
        self.node_id = node_id
        self.local_model = None

    def receive_global_model(self, model):
        self.local_model = model.copy()

    def train_local_model(self):
        # –ù–∞–≤—á–∞–Ω–Ω—è –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        for data_point in self.local_data:
            # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
            pass

        # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –≥—Ä–∞–¥—ñ—î–Ω—Ç—ñ–≤ (–Ω–µ –¥–∞–Ω–∏—Ö!)
        return self.calculate_model_updates()

    def calculate_model_updates(self):
        # –õ–∏—à–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ, –Ω–µ —Å–∞–º—ñ –¥–∞–Ω—ñ
        return {'node_id': self.node_id, 'gradients': [...]}
```

**üîí –ü–µ—Ä–µ–≤–∞–≥–∏:** –î–∞–Ω—ñ –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è –ª–æ–∫–∞–ª—å–Ω–æ, privacy

## –Ü—î—Ä–∞—Ä—Ö—ñ—á–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è

```mermaid
graph TB
    A1[Edge 1] --> B1[üìä Regional 1]
    A2[Edge 2] --> B1
    A3[Edge 3] --> B1

    A4[Edge 4] --> B2[üìä Regional 2]
    A5[Edge 5] --> B2
    A6[Edge 6] --> B2

    B1 --> C[‚òÅÔ∏è Cloud]
    B2 --> C

    C --> D[üåç Global Analytics]
    C --> E[ü§ñ Model Training]

    E -.->|–ú–æ–¥–µ–ª—ñ| B1
    E -.->|–ú–æ–¥–µ–ª—ñ| B2
```

**–ü—Ä–∏–Ω—Ü–∏–ø:** –õ–æ–∫–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ ‚Üí –†–µ–≥—ñ–æ–Ω–∞–ª—å–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è ‚Üí –ì–ª–æ–±–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑

## Offline-First –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```python
class OfflineFirstEdge:
    def __init__(self):
        self.is_online = False
        self.offline_queue = []

    def process_data(self, reading):
        # –û–±—Ä–æ–±–∫–∞ –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –∑'—î–¥–Ω–∞–Ω–Ω—è
        local_result = self.local_processing(reading)

        if self.is_online:
            try:
                self.send_to_cloud(reading)
                self.process_offline_queue()  # –û—á–∏—Å—Ç–∫–∞ —á–µ—Ä–≥–∏
            except:
                self.is_online = False
                self.queue_for_later(reading)
        else:
            self.queue_for_later(reading)

    def queue_for_later(self, reading):
        self.offline_queue.append(reading)

        # –£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–æ–º —á–µ—Ä–≥–∏
        if len(self.offline_queue) > 10000:
            self.aggregate_old_data()
```

## –ü—Ä–æ–º–∏—Å–ª–æ–≤–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥

### üè≠ **–ü—Ä–æ–≥–Ω–æ–∑–Ω–µ –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è**

```python
class PredictiveMaintenance:
    def analyze_equipment(self, equipment_id):
        # –Ü—Å—Ç–æ—Ä–∏—á–Ω—ñ –¥–∞–Ω—ñ –∑–∞ 24 –≥–æ–¥–∏–Ω–∏
        data = self.get_historical_data(equipment_id, hours=24)

        # –ê–Ω–∞–ª—ñ–∑ —Ç—Ä–µ–Ω–¥—ñ–≤
        vibration_trend = self.calculate_trend(data, 'vibration')
        temp_trend = self.calculate_trend(data, 'temperature')

        # –û—Ü—ñ–Ω–∫–∞ —Ä–∏–∑–∏–∫—É –≤—ñ–¥–º–æ–≤–∏
        risk_score = self.calculate_failure_risk(
            vibration_trend,
            temp_trend
        )

        if risk_score > 0.7:
            return {
                'status': 'critical',
                'recommendation': '–ù–µ–≥–∞–π–Ω–µ –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è',
                'ttf': self.estimate_time_to_failure(data)
            }
```

## –†–æ–∑—É–º–Ω—ñ –±—É–¥—ñ–≤–ª—ñ

```sql
-- –ê–Ω–∞–ª—ñ–∑ –µ–Ω–µ—Ä–≥–æ—Å–ø–æ–∂–∏–≤–∞–Ω–Ω—è
WITH hourly_consumption AS (
    SELECT
        time_bucket('1 hour', time) as hour,
        floor_number,
        sum(power_watts) / 1000.0 as kwh_consumed,
        avg(occupancy_count) as avg_occupancy
    FROM building_sensors
    GROUP BY hour, floor_number
)
SELECT
    hour,
    floor_number,
    kwh_consumed,
    CASE
        WHEN kwh_consumed > baseline + 2*stddev THEN '–ê–Ω–æ–º–∞–ª—ñ—è'
        ELSE '–ù–æ—Ä–º–∞'
    END as status
FROM hourly_consumption
```

**üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:** –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —Å–ø–æ–∂–∏–≤–∞–Ω–Ω—è –Ω–∞ 20-30%

## Precision Agriculture

### üåæ **–°–∏—Å—Ç–µ–º–∞ –∑—Ä–æ—à–µ–Ω–Ω—è**

```python
class IrrigationSystem:
    thresholds = {
        'wheat': {'min': 30, 'max': 60},
        'corn': {'min': 40, 'max': 70}
    }

    def analyze_field(self, field_id):
        zones = self.get_zone_data(field_id)

        plan = []
        for zone in zones:
            crop = self.get_crop_type(zone['id'])
            moisture = zone['avg_moisture']

            if moisture < self.thresholds[crop]['min']:
                water_needed = self.calculate_water(moisture, crop)
                plan.append({
                    'zone': zone['id'],
                    'action': 'irrigate',
                    'duration': water_needed
                })

        return plan
```

## –í–∏—Å–Ω–æ–≤–∫–∏

### üìä **–ß–∞—Å–æ–≤—ñ —Ä—è–¥–∏**

- –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ë–î: InfluxDB, TimescaleDB
- –ö–æ–º–ø—Ä–µ—Å—ñ—è 90-95%
- –ë–∞–≥–∞—Ç–æ—Ä—ñ–≤–Ω–µ–≤–∞ –∞–≥—Ä–µ–≥–∞—Ü—ñ—è

### üåê **IoT —Å–∏—Å—Ç–µ–º–∏**

- MQTT –¥–ª—è –∑–≤'—è–∑–∫—É
- –ü–æ—Ç–æ–∫–æ–≤–∞ –æ–±—Ä–æ–±–∫–∞
- –í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ

### üîß **Edge Computing**

- –ó–º–µ–Ω—à–µ–Ω–∞ –ª–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å
- –ê–≤—Ç–æ–Ω–æ–º–Ω–∞ —Ä–æ–±–æ—Ç–∞
- –§–µ–¥–µ—Ä–æ–≤–∞–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

### üè≠ **–ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è**

- –ü—Ä–æ–º–∏—Å–ª–æ–≤–∏–π –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥
- –†–æ–∑—É–º–Ω—ñ –±—É–¥—ñ–≤–ª—ñ
- –¢–æ—á–Ω–µ –∑–µ–º–ª–µ—Ä–æ–±—Å—Ç–≤–æ
